# Spark ETL Project Setup 
    Required Pieces of software: 
        1. Java 
        2. python 
        3. spark
        4. hadoop_winutils 
        5. pycharm

### Step:1 - Download & Install Java 8|11|17 + Windows Environment "JAVA_HOME"
![img_11.png](readme_resources/img_11.png)
### Step:2 - Download & Install Python 3.8 or later + Windows Environment "PYTHONPATH"
![img_10.png](readme_resources/img_10.png)

### Step:3 - Download and Setup Spark in Windows
#### Step:3.1 - Setup Spark 
![img.png](readme_resources/img.png)
![img_12.png](readme_resources/img_12.png)
#### Step:3.2 - Setup Hadoop Windows Utilities
![img_1.png](readme_resources/img_1.png)

### Step:4 - Download intellij pyCharm IDE Community Edition
#### Step:4.1 - Create Python Project for "pyspark"
![img_2.png](readme_resources/img_2.png)
![img_3.png](readme_resources/img_3.png)

#### Step:4.2 - Setup/Install "pyspark" for python Project
![img_4.png](readme_resources/img_4.png)
![img_5.png](readme_resources/img_5.png)
![img_6.png](readme_resources/img_6.png)

#### Step:4.3 - Edit runtime configuration for RUN "python + pyspark"
![img_7.png](readme_resources/img_7.png)
![img_8.png](readme_resources/img_8.png)
![img_9.png](readme_resources/img_9.png)

### Step:5 - Testing, Run & verify Script "data_pipline.py"